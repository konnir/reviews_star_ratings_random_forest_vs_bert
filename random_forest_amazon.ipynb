{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_155561/3820001236.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['verified'] = df_selected['verified'].astype(int)\n",
      "/tmp/ipykernel_155561/3820001236.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['category'] = df_selected['category'].astype('category')\n",
      "/tmp/ipykernel_155561/3820001236.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['category'] = df_selected['category'].cat.codes\n",
      "/tmp/ipykernel_155561/3820001236.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['price'] = df_selected['price'].str.extract('(\\d+\\.\\d+|\\d+)').astype(float)\n",
      "/tmp/ipykernel_155561/3820001236.py:28: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_selected['price'].fillna(df_selected['price'].mean(), inplace=True)\n",
      "/tmp/ipykernel_155561/3820001236.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['price'].fillna(df_selected['price'].mean(), inplace=True)\n",
      "/tmp/ipykernel_155561/3820001236.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['rating'] = df_selected['rating'].astype(int)\n",
      "/tmp/ipykernel_155561/3820001236.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected.dropna(inplace=True)\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train_non_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 77\u001b[0m\n\u001b[1;32m     70\u001b[0m X_text_test \u001b[38;5;241m=\u001b[39m encode_texts(X_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreviewText\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Prepare non-text features, normalize as necessary\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Here, add code to preprocess and prepare non-text features from X_train and X_test\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Combine BERT-encoded text features with other features\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# Assuming non-text features are prepared and stored in X_train_non_text and X_test_non_text\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m X_train_combined \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack([X_text_train, \u001b[43mX_train_non_text\u001b[49m])\n\u001b[1;32m     78\u001b[0m X_test_combined \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack([X_text_test, X_test_non_text])\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Train a Random Forest classifier\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_non_text' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'df_selected' is prepared as in your provided code\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('data/short_amazon_reviews.csv')\n",
    "\n",
    "# Preprocess your dataset as per your initial steps (not shown here for brevity)\n",
    "# Step 1: Keep only the required columns\n",
    "df_selected = df[['verified', 'category', 'price', 'rating', 'reviewText']]\n",
    "# Step 2: Convert 'verified' from boolean to 0 and 1\n",
    "df_selected['verified'] = df_selected['verified'].astype(int)\n",
    "# Step 3: Convert 'category' to numbers and save the dictionary for conversion\n",
    "df_selected['category'] = df_selected['category'].astype('category')\n",
    "category_mapping = dict(enumerate(df_selected['category'].cat.categories))\n",
    "df_selected['category'] = df_selected['category'].cat.codes\n",
    "# More thorough cleaning of the 'price' column to ensure it only contains valid numeric strings\n",
    "df_selected['price'] = df_selected['price'].str.extract('(\\d+\\.\\d+|\\d+)').astype(float)\n",
    "# Fill nulls in 'price' with the mean of the column, now that it's properly cleaned\n",
    "df_selected['price'].fillna(df_selected['price'].mean(), inplace=True)\n",
    "# Attempt to convert 'rating' to int again\n",
    "df_selected['rating'] = df_selected['rating'].astype(int)\n",
    "# Remove any remaining nulls from the dataframe\n",
    "df_selected.dropna(inplace=True)\n",
    "df_selected.head()\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "# Assuming df_selected is your final preprocessed DataFrame ready for modeling\n",
    "X = df_selected.drop('rating', axis=1)\n",
    "y = df_selected['rating']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Initialize BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to encode texts and average BERT outputs\n",
    "def encode_texts(texts):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    encoded_features = []\n",
    "    for text in texts:\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=64,  # Ensure we do not exceed BERT's max length\n",
    "            truncation=True,  # Truncate texts that exceed the max length\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        with torch.no_grad():  # Ensure no gradients are calculated\n",
    "            output = model(encoded_dict['input_ids'], encoded_dict['attention_mask'])\n",
    "            # Take the mean of the embeddings for the sequence\n",
    "            feature = output.last_hidden_state.mean(dim=1).squeeze().detach().cpu().numpy()\n",
    "            encoded_features.append(feature)\n",
    "    return np.array(encoded_features)\n",
    "\n",
    "\n",
    "# Encode the review texts\n",
    "X_text_train = encode_texts(X_train['reviewText'].tolist())\n",
    "X_text_test = encode_texts(X_test['reviewText'].tolist())\n",
    "\n",
    "# Prepare non-text features, normalize as necessary\n",
    "# Here, add code to preprocess and prepare non-text features from X_train and X_test\n",
    "\n",
    "# Combine BERT-encoded text features with other features\n",
    "# Assuming non-text features are prepared and stored in X_train_non_text and X_test_non_text\n",
    "X_train_combined = np.hstack([X_text_train, X_train_non_text])\n",
    "X_test_combined = np.hstack([X_text_test, X_test_non_text])\n",
    "\n",
    "# Train a Random Forest classifier\n",
    "clf = make_pipeline(StandardScaler(), RandomForestClassifier(random_state=42))\n",
    "clf.fit(X_train_combined, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Training accuracy:\", clf.score(X_train_combined, y_train))\n",
    "print(\"Test accuracy:\", clf.score(X_test_combined, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "velotix-ex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
